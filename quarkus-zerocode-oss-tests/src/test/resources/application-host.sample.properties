# Sample of application-host.properties written to target/test-classes using the
# Maven write-properties-file-maven-plugin (see pom.xml)

# --------------------------------
# ZeroCode REST related properties
# --------------------------------

corporate.proxy.host=
corporate.proxy.port=80
corporate.proxy.username=
corporate.proxy.password=

http.max.timeout.milliseconds=10000

web.application.endpoint.host=http\://localhost\:8084
web.application.endpoint.context=

# --------------------------------
# Our custom JDBC properties
# --------------------------------
jdbc.driver.class=org.postgresql.Driver

fight.jdbc.url=jdbc\:postgresql\://localhost\:5432/fights_database
fight.jdbc.username=superfight
fight.jdbc.password=superfight

hero.jdbc.url=jdbc\:postgresql\://localhost\:5432/heroes_database
hero.jdbc.username=superman
hero.jdbc.password=superman

villain.jdbc.url=jdbc\:postgresql\://localhost\:5432/villains_database
villain.jdbc.username=superbad
villain.jdbc.password=superbad


# --------------------------------
# ZeroCode properties
# --------------------------------

kafka.bootstrap.servers=localhost\:9092

kafka.producer.properties=kafka-servers/kafka-producer.properties
kafka.consumer.properties=kafka-servers/kafka-consumer.properties


# --------------------------------------------------------------------
# Optional local consumer properties common/central to all test cases.
# These can be overwritten by the tests locally.
# --------------------------------------------------------------------
# If this property is set, then the consumer does a commitSync after reading the message(s)
# Make sure you don't set both commitSync and commitAsync to true
consumer.commitSync = true

# If this property is set, then the consumer does a commitAsync after reading the message(s)
# Make sure you don't set both commitSync and commitAsync to true
consumer.commitAsync = false

# All records those were read are dumped to this specified file path
# This path can be a relative path or an absolute path. If the file
# does not exist, it creates the file and dumps the records
consumer.fileDumpTo= target/logs/kafka-consumed-records.txt

# If this property is set to true, all records are shown in the response.
# When dealing with large number of records, you might not be interested
# in the individual records, but interested in the recordCount
# i.e. total number of records consumed
consumer.showRecordsConsumed=false

# That means if any record(s) are read, then this counter is reset to 0(zero) and the consumer
# polls again. So if no records are fetched for a specific poll interval, then the consumer
# gives a retry retrying until this max number polls/reties reached.
consumer.maxNoOfRetryPollsOrTimeouts=5

# Polling time in milli seconds i.e how long the consumer should poll before
# the next retry poll
consumer.pollingTime = 1000
